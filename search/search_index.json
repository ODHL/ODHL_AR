{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"rAcecaR: Antimicrobial Resistance (AR) Bioinformatics Pipeline","text":"<p>\ud83d\udea8 Warning \ud83d\udea8 The results generated by this pipeline are not CLIA certified and should not be considered diagnostic.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>The ODHL_rAcecaR pipeline is designed for the detection and characterization of antimicrobial resistance (AMR) genes and other relevant genomic features from high-throughput sequencing data. This pipeline processes bacterial whole genome sequencing (WGS) and metagenomic sequencing data to identify antimicrobial resistance determinants, sequence types, and genomic features relevant to public health surveillance and epidemiological investigations.</p> <p>This workflow is developed and maintained by the <code>Ohio Department of Health Laboratory (ODHL)</code> and is built using <code>Nextflow</code>, a robust workflow management system that ensures reproducibility and scalability across HPC clusters, cloud environments, and local machines. The pipeline was built off the work of the <code>CDC Phoenix Pipeline</code>. The workflow leverages <code>Docker</code> and <code>Singularity containers</code> to provide a standardized execution environment. </p>"},{"location":"#pipeline-workflow","title":"Pipeline Workflow","text":"<p>The ODHL_rAcecaR pipeline consists of the following stages:</p>"},{"location":"#1-read-quality-control-qc","title":"1. Read Quality Control (QC)","text":"<ul> <li>Tool: <code>FastQC</code> </li> <li>Purpose: Evaluates sequencing read quality for potential issues such as adapter contamination and sequencing errors.</li> </ul>"},{"location":"#2-read-trimming-and-filtering","title":"2. Read Trimming and Filtering","text":"<ul> <li>Tool: <code>Fastp</code> </li> <li>Purpose: Removes low-quality bases and adapter sequences to improve downstream analysis.</li> </ul>"},{"location":"#3-taxonomic-classification","title":"3. Taxonomic Classification","text":"<ul> <li>Tool: <code>Kraken2</code> </li> <li> <p>Purpose: Assigns taxonomic labels to sequencing reads based on a comprehensive reference database.</p> </li> <li> <p>Tool: <code>Krona</code> </p> </li> <li>Purpose: Generates interactive visualizations of taxonomic classification results.</li> </ul>"},{"location":"#4-genome-assembly-and-quality-assessment","title":"4. Genome Assembly and Quality Assessment","text":"<ul> <li>Tool: <code>SPAdes</code> </li> <li> <p>Purpose: Performs de novo genome assembly from short-read sequencing data.</p> </li> <li> <p>Tool: <code>QUAST</code> </p> </li> <li>Purpose: Assesses the quality and completeness of genome assemblies.</li> </ul>"},{"location":"#5-sequence-typing-resistance-gene-detection","title":"5. Sequence Typing &amp; Resistance Gene Detection","text":"<ul> <li>Tool: <code>MLST</code> </li> <li> <p>Purpose: Identifies sequence types (STs) of bacterial genomes for epidemiological tracking.</p> </li> <li> <p>Tool: <code>AMRFinderPlus</code> </p> </li> <li>Purpose: Detects known antimicrobial resistance (AMR) genes and point mutations associated with resistance.</li> </ul>"},{"location":"#6-plasmid-virulence-gene-identification","title":"6. Plasmid &amp; Virulence Gene Identification","text":"<ul> <li>Tool: <code>PlasmidFinder</code> </li> <li> <p>Purpose: Identifies plasmid sequences associated with resistance gene transmission.</p> </li> <li> <p>Tool: <code>Gamma</code> </p> </li> <li>Purpose: Detects horizontally transferred genes associated with virulence and resistance.</li> </ul>"},{"location":"#7-phylogenetic-analysis-similarity-metrics","title":"7. Phylogenetic Analysis &amp; Similarity Metrics","text":"<ul> <li>Tool: <code>FastANI</code> </li> <li> <p>Purpose: Measures genome-wide similarity between bacterial isolates.</p> </li> <li> <p>Tool: <code>Mash</code> </p> </li> <li>Purpose: Quickly estimates genetic distance between samples for clustering analyses.</li> </ul>"},{"location":"#input-requirements","title":"Input Requirements","text":"<p>The ODHL_rAcecaR pipeline processes paired-end or single-end Illumina sequencing reads in FASTQ format. A sample sheet (CSV/TSV) should be provided with metadata for each sample with other input. View the  <code>Getting Started page</code> and <code>Preparing Files page</code> for more information.for more information.</p>"},{"location":"#output-summary","title":"Output Summary","text":"<p>View the  <code>Output page</code> for more information.</p>"},{"location":"#citations-acknowledgments","title":"Citations &amp; Acknowledgments","text":"<p>This pipeline was developed by the Ohio Department of Health Laboratory (ODHL) to support public health surveillance of antimicrobial resistance (AMR). For contribution and contact information, view the <code>contribution page</code>.</p>"},{"location":"user-guide/contributions/","title":"Contributions","text":"<p><code>rAcecaR</code> was largely developed by <code>Ohio Department of Health Laboratory (ODHL)</code>:</p> <ul> <li>Sevilla, S.</li> </ul>"},{"location":"user-guide/contributions/#contact","title":"Contact","text":"<p>Questions and comments can be sent via email to: samantha.chill@odh.ohio.gov.</p>"},{"location":"user-guide/contributions/#for-more-information-visit","title":"For more information, visit:","text":"<p>\ud83d\udd17 ODHL AR Pipeline Repository \ud83d\udd17 Ohio Public Health Laboratory</p>"},{"location":"user-guide/getting-started/","title":"Getting Started","text":""},{"location":"user-guide/getting-started/#introduction","title":"Introduction","text":"<p>ODHL_AR is a bioinformatics best-practice pipeline for detecting antimicrobial resistance (AMR) genes and assessing bacterial genomic characteristics from whole-genome sequencing (WGS) data.</p> <p>The pipeline is built using Nextflow, a workflow tool that efficiently runs tasks across multiple compute infrastructures in a portable and scalable manner. It uses Docker/Singularity containers, making installation trivial and ensuring reproducible results.</p>"},{"location":"user-guide/getting-started/#pipeline-summary","title":"Pipeline Summary","text":"<ol> <li>Read QC: <code>FastQC</code> \u2013 Provides quality metrics for raw sequencing reads.</li> <li>Trimming reads: <code>Fastp</code> \u2013 Trims low-quality reads and adapter sequences.</li> <li>Taxonomic Classification: <code>Kraken2</code> \u2013 Identifies bacterial species present in the sequencing data.</li> <li>Genome Assembly: <code>SPAdes</code> \u2013 Performs de novo genome assembly.</li> <li>Quality Assessment of Assembly: <code>QUAST</code> \u2013 Evaluates assembly quality.</li> <li>Plasmid Identification: <code>PlasmidFinder</code> \u2013 Detects plasmids in the assembled genome.</li> <li>MLST Typing: <code>MLST</code> \u2013 Determines Multilocus Sequence Typing (MLST) for bacterial isolates.</li> <li>AMR Gene Detection: <code>AMRFinderPlus</code> \u2013 Identifies antimicrobial resistance genes.</li> <li>Virulence Gene Detection: <code>Gamma</code> \u2013 Predicts bacterial virulence factors.</li> <li>Genome Annotation: <code>Prokka</code> \u2013 Annotates genomic features.</li> <li>Whole-Genome Comparisons:<ul> <li><code>Mash</code> \u2013 Estimates genome distances for clustering.</li> <li><code>FastANI</code> \u2013 Calculates Average Nucleotide Identity (ANI) for species identification.</li> </ul> </li> <li>Final Report: <code>MultiQC</code> \u2013 Summarizes results across all samples in a single interactive report.</li> </ol>"},{"location":"user-guide/getting-started/#entry-points","title":"Entry Points","text":"<p>Currently, there are several entry points for the AR pipeline:</p> <ol> <li><code>arBASESPACE</code>: Downloads files directly from Illumina Basespace.</li> <li><code>arANALYSIS</code>: Downloads file Illumina Basespace, if needed; performs quality control, genome assembly, and taxonomic classification; detects antimicrobial resistance genes, plasmids, and virulence factors; performs generation of unique WGS ID's; preparaes NCBI submission.</li> <li><code>DBProcessing</code>: Performs quality control, compiles NCBI ID's into a compiled user file.</li> </ol> <p>In addition there are several entry points for AR outbreak analysis. 1. <code>outbreakANALYSIS</code>: Performs additional analysis for outbreak detection. 2. <code>outbreakREPORTING</code>: Generates reports depending on the type of outbreak analysis required. 3. <code>NFCORE_OUTBREAK</code>: Executes outbreakANALYSIS and outbreakREPORTING for an second end-to-end workflow.</p>"},{"location":"user-guide/getting-started/#processes","title":"Processes","text":""},{"location":"user-guide/getting-started/#quality-control-preprocessing","title":"Quality Control &amp; Preprocessing","text":"<ul> <li>FastQC: Provides sequencing quality metrics.</li> <li>Fastp: Trims low-quality reads and removes adapters.</li> <li>Kraken2: Classifies bacterial species from sequencing data.</li> </ul>"},{"location":"user-guide/getting-started/#genome-assembly-assessment","title":"Genome Assembly &amp; Assessment","text":"<ul> <li>SPAdes: Performs de novo genome assembly.</li> <li>QUAST: Evaluates assembly quality.</li> <li>PlasmidFinder: Identifies plasmid sequences in assembled genomes.</li> </ul>"},{"location":"user-guide/getting-started/#genotyping-comparative-genomics","title":"Genotyping &amp; Comparative Genomics","text":"<ul> <li>MLST: Identifies bacterial strain types.</li> <li>Mash: Estimates genetic distances between isolates.</li> <li>FastANI: Computes Average Nucleotide Identity (ANI) for species classification.</li> </ul>"},{"location":"user-guide/getting-started/#antimicrobial-resistance-virulence-detection","title":"Antimicrobial Resistance &amp; Virulence Detection","text":"<ul> <li>AMRFinderPlus: Detects AMR genes in bacterial genomes.</li> <li>Gamma: Predicts virulence factors from genomic data.</li> </ul>"},{"location":"user-guide/getting-started/#genome-annotation","title":"Genome Annotation","text":"<ul> <li>Prokka: Annotates bacterial genomes.</li> </ul>"},{"location":"user-guide/getting-started/#final-reports","title":"Final Reports","text":"<ul> <li>MultiQC: Compiles a summary of all quality control and analysis results.</li> </ul>"},{"location":"user-guide/getting-started/#dependencies","title":"Dependencies","text":""},{"location":"user-guide/getting-started/#software-tools","title":"Software &amp; Tools","text":"<p>Ensure that the following software is installed before running the pipeline:</p> <ul> <li><code>Nextflow</code> (<code>&gt;=21.04.0</code>)</li> <li><code>Docker</code> or <code>Singularity</code></li> <li><code>Conda</code> (Optional)</li> </ul>"},{"location":"user-guide/getting-started/#core-software-versions","title":"Core Software Versions","text":"<p>The pipeline requires the following tools:</p> <pre><code>- Python 3.9\n- Samtools 1.21\n- FastQC 0.12.1\n- Fastp 0.23.4\n- Kraken2 2.1.2\n- SPAdes 3.15.5\n- QUAST 5.0.2\n- PlasmidFinder 2.1\n- MLST 2.23.0\n- Mash 2.3\n- FastANI 1.33\n- AMRFinderPlus 3.10\n- Gamma 2.2\n- Prokka 1.14.5\n- MultiQC 1.21\n</code></pre>"},{"location":"user-guide/getting-started/#reference-databases","title":"Reference Databases","text":""},{"location":"user-guide/getting-started/#kraken2-db","title":"Kraken2 DB","text":"<p>The database file can be taken from <code>Ben Langmead's repository</code> which links directly to the database file. It is recommended to use the latest version of the <code>8GB database</code>, and reformat it using the <code>bin/reformat_kraken.sh</code> script.</p>"},{"location":"user-guide/getting-started/#pipeline-execution","title":"Pipeline Execution","text":"<p>The ODHL_rAcecaR pipeline is implemented using Nextflow, which allows for execution on local machines, HPC clusters, or cloud environments.</p>"},{"location":"user-guide/getting-started/#1-install-nextflow","title":"1. Install Nextflow","text":"<pre><code>curl -s https://get.nextflow.io | bash\nmv nextflow ~/bin/\n</code></pre>"},{"location":"user-guide/getting-started/#2-clone-the-repository","title":"2. Clone the Repository","text":"<pre><code>git clone https://github.com/ODHL/ODHL_rAcecaR.git\ncd ODHL_rAcecaR\n</code></pre>"},{"location":"user-guide/getting-started/#3-configure-the-pipeline","title":"3. Configure the Pipeline","text":"<p>Modify the Nextflow configuration file (<code>nextflow.config</code>) to specify reference databases and execution profiles.</p> <p>Example modification: <pre><code>params {\nkraken2_db = \"/home/ubuntu/refs/k2/k2_standard_08gb_202412.tar.gz\"\namrfinder_db = \"/home/ubuntu/refs/amrfinderplus/latest\"\nplasmidfinder_db = \"/home/ubuntu/refs/plasmidfinder/latest\"\n}\n</code></pre></p>"},{"location":"user-guide/getting-started/#4-optional-install-basespace","title":"*** 4. (Optional) Install Basespace**","text":"<p>The pipeline allows for automatic download from basespace. If you choose to use this feature, you'll need to add basespace to your $PATH. <pre><code># Install basespace\n## Docs\n## https://developer.basespace.illumina.com/docs/content/documentation/cli/cli-overview\nif [[ ! -d $HOME/tools/ ]]; then mkdir -p $HOME/tools/; done\nwget \"https://launch.basespace.illumina.com/CLI/latest/amd64-linux/bs\" -O $HOME/tools/basespace\nchmod u+x $HOME/tools/basespace\n./basespace auth\n### follow path to website and sign in\n### should display \"Welcome [name of user]\n</code></pre></p>"},{"location":"user-guide/getting-started/#reproducibility","title":"Reproducibility","text":"<p>To ensure consistent results, specify the pipeline version when running:</p> <pre><code>nextflow run ODHL/ODHL_AR -r 1.0.0\n</code></pre> <p>You can check for the latest version on the ODHL/ODHL_AR GitHub Releases page.</p>"},{"location":"user-guide/output/","title":"4. Expected Output","text":"Output Type Description QC Reports FastQC and MultiQC summary reports Trimmed Reads Quality-filtered sequencing reads (FASTQ) Taxonomic Classification Kraken2 classification reports &amp; Krona plots Genome Assembly SPAdes-assembled contigs (FASTA) AMR &amp; Virulence Gene Detection AMRFinderPlus, PlasmidFinder, and Gamma results Phylogenetic &amp; Similarity Analysis FastANI and Mash distance matrices"},{"location":"user-guide/preparing-files/","title":"Input Format","text":""},{"location":"user-guide/preparing-files/#samplesheet-required","title":"Samplesheet (Required)","text":"<p>Each project requires an <code>input</code> CSV formatted file.</p> Sample ID Read 1 Read 2 Sample1 Sample1_R1.fastq.gz Sample1_R2.fastq.gz Sample2 Sample2_R1.fastq.gz Sample2_R2.fastq.gz <pre><code>sample,fastq_1,fastq_2\nsample1,/path/to/fastq/files/sample1.R1.fastq.gz,/path/to/fastq/files/sample1.R2.fastq.gz\nsample2,/path/to/fastq/files/sample2.R1.fastq.gz,/path/to/fastq/files/sample2.R2.fastq.gz\n</code></pre>"},{"location":"user-guide/preparing-files/#labresults-optional","title":"labResults (Optional)","text":"<p>Each project can check laboratory QC with an <code>labResults</code> CSV formatted file.</p> Sample ID Results Sample1 expectedSpecies Sample2 expectedSpecie2 <pre><code>sample,results\nsample1,expectedSpecies\nsample2,expectedSpecies2\n</code></pre>"},{"location":"user-guide/preparing-files/#metadata_ncbi-optional","title":"metadata_NCBI (Optional)","text":"<p>Each project can upload to NCBI with an <code>metadata_NCBI</code> tab formatted file.</p> Specimen ID Last Name First Name Birth Date Sex City State ZIP Code County Specimen Host Isolation Source Source Other Healthcare Origin Healthcare State Healthcare ZIP Submitter Name Submitter State Submitter ZIP Organism Genus Organism Species Collect Date Date Received sample1 person1 person1 9/19/1948 1 ATHENS OH 45701 ATHENS 1 SWAB_WOUND LAURELS OF ATHENS, THE OH 45701 HEALTH_ASSOCIATES OH 44132 ACINETOBACTER BAUMANNII 8/6/2024 8/14/2024 sample2 person2 person2 4/26/1953 2 LEBANON IL 62254 ST. CLAIR 1 SWAB_WOUND IL HEALTH_ASSOCIATES OH 44132 ACINETOBACTER BAUMANNII 7/31/2024 8/14/2024 sample3 person3 person3 3/17/1957 1 BELLEVUE OH 44811 SANDUSKY 1 URINE_CATHETER (STRAIGHT) CLEVELAND CLINIC OH 44195 HEALTH_ASSOCIATES OH 44106 PSEUDOMONAS AERUGINOSA 8/11/2024 8/16/2024 <pre><code>specimen_id name_last   name_first  birth_date  sex pt_city pt_state    pt_zip  pt_county   specimen_host   isolation_source    source_other    healthcare_origin   healthcare_state    healthcare_zip  submitter_name  submitter_state submitter_zip   organism_genus  organism_species    collect_date    date_received\nsample1 person1 person1 9/19/1948   1   ATHENS  OH  45701   ATHENS  1   SWAB_WOUND      LAURELS OF ATHENS, THE  OH  45701   HEALTH_ASSOCIATES   OH  44132   ACINETOBACTER   BAUMANNII   8/6/2024    8/14/2024\nsample2 person2 person2 4/26/1953   2   LEBANON IL  62254   ST. CLAIR   1   SWAB_WOUND          IL      HEALTH_ASSOCIATES   OH  44132   ACINETOBACTER   BAUMANNII   7/31/2024   8/14/2024\nsample3 person3 person3 3/17/1957   1   BELLEVUE    OH  44811   SANDUSKY    1   URINE_CATHETER (STRAIGHT)       CLEVELAND CLINIC    OH  44195   HEALTH_ASSOCIATES   OH  44106   PSEUDOMONAS AERUGINOSA  8/11/2024   8/16/2024\n</code></pre>"},{"location":"user-guide/preparing-files/#reference-databases","title":"Reference Databases","text":""},{"location":"user-guide/preparing-files/#kraken2-database","title":"Kraken2 Database","text":"<p>The database file can be taken from <code>Ben Langmead's repository</code> which links directly to the database file. It is recommended to use the latest version of the <code>8GB database</code>, and reformat it using the <code>bin/reformat_kraken.sh</code> script.</p> <pre><code>#!/bin/bash\n# bash reformat_kraken2.sh 202401 k2_standard_08gb_20240112.tar.gz\n\ntag=$1\nkraken_db=$2\nkraken_output=\"k2_standard_08gb_reformat_${tag}.tar.gz\"\n\nif [[ ${kraken_db} == *.tar.gz ]]; then\necho \"Preparing K2 directory: from ${kraken_db} to  ${kraken_output}\"\n\n# Use standard gzip for decompression\ntar -xzf \"${kraken_db}\" || {\necho \"Error: Failed to extract ${kraken_db}\" &gt;&amp;2\nexit 1\n}\n\n# create the final dir\nmkdir -p \"${kraken_output}\"\nmv *.kmer_distrib *.k2d seqid2taxid.map inspect.txt ktaxonomy.tsv \"${kraken_output}\" 2&gt;/dev/null || {\necho \"Warning: Some expected files were not found.\"\n}\nelif\necho \"Output already exists: ${kraken_output}\"\nfi\n</code></pre>"},{"location":"user-guide/preparing-files/#all-other-databases","title":"All Other Databases","text":"<p>All other databases come pre-packaged with the pipeline</p> <pre><code>- REFSEQ_20240124_Bacteria_complete.msh.gz\n- mlst_db_20240124.tar.gz\n- phiX.fasta\n- nodes_20240129.dmp.gz\n- names_20240129.dmp.gz\n- HyperVirulence_20220414.fasta\n- ResGANNCBI_20240131_srst2.fasta\n- PF-Replicons_20240124.fasta\n- amrfinderdb_v3.12_20240131.1.tar.gz\n- NCBI_Assembly_stats_20240124.txt\n</code></pre>"},{"location":"user-guide/run/","title":"Run the Pipeline","text":"<p>To execute with Docker: <pre><code>nextflow run main.nf -profile docker\n</code></pre> To execute with Singularity: <pre><code>nextflow run main.nf -profile singularity\n</code></pre> To execute with the provided wrapper: <pre><code>bash run_workflow.sh \\\n-e &lt;entry&gt; \\ #REQUIRED: arBASESPACE,arANALYSIS,DBProcessing,outbreakANALYSIS,outbreakREPORTING,NFCORE_OUTBREAK\"\n-i &lt;projectID&gt; \\ #REQUIRED: test\n-r &lt;resumeRun&gt; \\ #OPTIONAL: Y,N (default Y)\n-o &lt;outbreakReportFlag&gt; #OPTIONAL: basic, advanced\n-n &lt;nextflowParams&gt; #OPTIONAL: nextflow configs (default -profile docker,test -entry NFCORE_ODHLAR --max_memory 7.GB --max_cpus 4)\n</code></pre></p>"},{"location":"user-guide/test-info/","title":"Test data","text":""},{"location":"user-guide/test-info/#overview","title":"Overview","text":"<p>Four test samples are included with the pipeline. Two samples will fail tresholds (one failing pipeline thresholds, one failing the labroatory threshold) and two which will pass.</p>"},{"location":"user-guide/test-info/#samplesheet","title":"Samplesheet","text":"<p>sample,fastq_1,fastq_2 sample1,sample1.R1.fastq.gz,sample1.R2.fastq.gz sample2,sample2.R1.fastq.gz,sample2.R2.fastq.gz sample3,sample3.R1.fastq.gz,sample3.R2.fastq.gz sample4,sample4.R1.fastq.gz,sample4.R2.fastq.gz</p>"},{"location":"user-guide/test-info/#lab-results","title":"Lab Results","text":"<p>sample,results sample,results sample1,Providencia sample2,Acinetobacter sample3,Klebsiella sample4,Pseudomonas</p>"},{"location":"user-guide/test-info/#expected-results","title":"Expected Results","text":""},{"location":"user-guide/test-info/#sample1","title":"Sample1","text":"<p>This sample will fail QC thesholds. KRAKEN2_CLASSIFY_WEIGHTED     : FAILED   : Genus-Acinetobacter is under 70% (species-baumannii 66.25%), likely contaminated ASSEMBLY_RATIO(SD)            : FAILED   : St. dev. too large - 1.8449x(7.4691-SD) against P.stuartii COVERAGE                      : FAILED   : 4.16x coverage based on trimmed reads (Min:30x)</p>"},{"location":"user-guide/test-info/#sample2","title":"Sample2","text":"<p>This sample will pass all QC thresholds.</p>"},{"location":"user-guide/test-info/#sample3","title":"Sample3","text":"<p>This sample will fail QC thresholds. The results should be Pseudomonas, but reported as Klebsiella</p>"},{"location":"user-guide/test-info/#sample4","title":"Sample4","text":"<p>This sample will pass all QC thresholdss.</p>"},{"location":"user-guide/test-info/#running-pipeline","title":"Running pipeline","text":"<p>To execute with Docker: <pre><code>nextflow run main.nf -entry arANALYSIS -profile docker,test\n</code></pre> To execute with Singularity: <pre><code>nextflow run main.nf -entry arANALYSIS -profile singularity,test\n</code></pre> To execute with the provided wrapper: <pre><code>bash run_workflow.sh \\\n-e arANALYSIS \\\n-i test\n</code></pre></p>"}]}